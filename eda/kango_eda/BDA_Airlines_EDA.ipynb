{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Importing AWS Glue Stuff**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# glue libraries and settings from guide notebook\n",
        "\n",
        "# %idle_timeout 2880\n",
        "# %glue_version 4.0\n",
        "# %worker_type G.1X\n",
        "# %number_of_workers 5\n",
        "\n",
        "# import sys\n",
        "# from awsglue.transforms import *\n",
        "# from awsglue.utils import getResolvedOptions\n",
        "# from pyspark.context import SparkContext\n",
        "# from awsglue.context import GlueContext\n",
        "# from awsglue.job import Job\n",
        "  \n",
        "# sc = SparkContext.getOrCreate()\n",
        "# glueContext = GlueContext(sc)\n",
        "# spark = glueContext.spark_session\n",
        "# job = Job(glueContext)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCGv7VrijWzc"
      },
      "source": [
        "#### **Import Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omIxSKCdzlYs",
        "outputId": "a38147ff-eeff-4380-d58f-fd350225f981"
      },
      "outputs": [],
      "source": [
        "# import python libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for local\n",
        "df = pd.read_csv('./datasets/airline.csv', encoding = \"ISO-8859-1\")\n",
        "holiday = pd.read_csv('./datasets/dim_date_proposed.csv')\n",
        "\n",
        "# # for running on AWS Glue\n",
        "# airline_dyf = glueContext.create_dynamic_frame.from_catalog(database='facts_database', table_name='airline.csv')\n",
        "# df = airline_dyf.toDF()\n",
        "\n",
        "# holiday_dyf = glueContext.create_dynamic_frame.from_catalog(database='facts_database', table_name='dim_date_proposed_csv')\n",
        "# # holiday = holiday_dyf.toDF()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8pd5qP-jfUQ"
      },
      "source": [
        "### **Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlbN7DGym8Gs"
      },
      "source": [
        "#### **holiday.csv dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4W1sHi6kjfjs",
        "outputId": "9a972ee8-0913-45b5-b0a8-956a3b405c2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/26/1987' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1987' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1987' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1987' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/24/1988' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1988' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1988' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1988' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/23/1989' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1989' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1989' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1989' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/22/1990' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1990' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1990' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1990' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/28/1991' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1991' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1991' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1991' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/26/1992' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1992' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1992' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1992' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/25/1993' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1993' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1993' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1993' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/24/1994' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1994' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1994' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1994' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/23/1995' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1995' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1995' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1995' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/28/1996' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1996' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1996' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1996' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/27/1997' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1997' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1997' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1997' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/26/1998' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1998' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1998' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1998' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/25/1999' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/1999' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/1999' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/1999' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/23/2000' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/2000' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/2000' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/2000' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/22/2001' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/2001' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/2001' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/2001' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/28/2002' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/2002' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/2002' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/2002' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/27/2003' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/2003' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/2003' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/2003' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/25/2004' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/2004' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/2004' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/2004' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/24/2005' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/2005' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/2005' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/2005' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/23/2006' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/2006' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/2006' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/2006' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/22/2007' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/2007' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/2007' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/2007' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '11/27/2008' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/24/2008' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/25/2008' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
            "C:\\Users\\zhenx\\AppData\\Local\\Temp\\ipykernel_27016\\4087044726.py:15: UserWarning: Parsing '12/31/2008' in MM/DD/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day_dt</th>\n",
              "      <th>holiday_us</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14610</th>\n",
              "      <td>1987-01-01</td>\n",
              "      <td>New Years Day</td>\n",
              "      <td>1987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14628</th>\n",
              "      <td>1987-01-19</td>\n",
              "      <td>MLK Day</td>\n",
              "      <td>1987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14656</th>\n",
              "      <td>1987-02-16</td>\n",
              "      <td>Presidents Day</td>\n",
              "      <td>1987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14754</th>\n",
              "      <td>1987-05-25</td>\n",
              "      <td>Memorial Day</td>\n",
              "      <td>1987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14794</th>\n",
              "      <td>1987-04-07</td>\n",
              "      <td>Independence Day</td>\n",
              "      <td>1987</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          day_dt        holiday_us  year\n",
              "14610 1987-01-01     New Years Day  1987\n",
              "14628 1987-01-19           MLK Day  1987\n",
              "14656 1987-02-16    Presidents Day  1987\n",
              "14754 1987-05-25      Memorial Day  1987\n",
              "14794 1987-04-07  Independence Day  1987"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#remove non-holidays\n",
        "holiday_cleaned = holiday[holiday['holiday_us'].notnull()]\n",
        "\n",
        "#include only holidays we need in the years in airline.csv (1987 - 2008)\n",
        "holiday_cleaned = holiday_cleaned[(holiday_cleaned['cal_year'] >= 1987) & (holiday_cleaned['cal_year'] <= 2008)]\n",
        "\n",
        "#remove unncessary columns\n",
        "holiday_cleaned = holiday_cleaned[['day_dt','holiday_us']]\n",
        "\n",
        "#add year column\n",
        "holiday_cleaned[\"year\"] = holiday_cleaned[\"day_dt\"].str[-4:]\n",
        "holiday_cleaned[\"year\"].astype(int)\n",
        "\n",
        "#change the format of day_dt column from mm/dd/yyyy to dd/mm/yyyy\n",
        "holiday_cleaned['day_dt'] = pd.to_datetime(holiday_cleaned['day_dt'], dayfirst=True)\n",
        "\n",
        "holiday_cleaned.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmL2dERVnJ-g"
      },
      "source": [
        "#### **airline.csv dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "HToJ4HTMnRCw",
        "outputId": "7b03b71b-a5bb-48bb-949f-e63eb3dcc301"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 1.08 GiB for an array with shape (15, 9674807) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#remove rows with ArrTime > 2400\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df1 \u001b[38;5;241m=\u001b[39m df1[(df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArrTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2400\u001b[39m)]\n\u001b[1;32m---> 11\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDepTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2400\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m df1\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     15\u001b[0m df2 \u001b[38;5;241m=\u001b[39m df1\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActualElapsedTime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirTime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArrTime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRSArrTime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRSDepTime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRSElapsedTime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCancellationCode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlightNum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTailNum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaxiIn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaxiOut\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUniqueCarrier\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3496\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3494\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   3495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 3496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3498\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3499\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   3500\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3551\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3549\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[0;32m   3550\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 3551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:3716\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3709\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3710\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3711\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3714\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3715\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3716\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3717\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:3703\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3699\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_take((), kwargs)\n\u001b[0;32m   3701\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m-> 3703\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m   3705\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:897\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    894\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    896\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 897\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:689\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    682\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    683\u001b[0m         indexer,\n\u001b[0;32m    684\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    685\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    686\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    687\u001b[0m     )\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 689\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    690\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    691\u001b[0m             indexer,\n\u001b[0;32m    692\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    693\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    694\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[0;32m    695\u001b[0m             ),\n\u001b[0;32m    696\u001b[0m         )\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    698\u001b[0m     ]\n\u001b[0;32m    700\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    701\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:690\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    682\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    683\u001b[0m         indexer,\n\u001b[0;32m    684\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    685\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    686\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    687\u001b[0m     )\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 690\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    698\u001b[0m     ]\n\u001b[0;32m    700\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    701\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\blocks.py:1139\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1137\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1139\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;66;03m#  this assertion\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m new_mgr_locs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\array_algos\\take.py:158\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    156\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    161\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m func(arr, indexer, out, fill_value)\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.08 GiB for an array with shape (15, 9674807) and data type float64"
          ]
        }
      ],
      "source": [
        "#create full_date column\n",
        "df1 = df\n",
        "df1[\"full_date\"] = df[\"DayofMonth\"].astype(str) + \"/\" + df[\"Month\"].astype(str) + \"/\" + df[\"Year\"].astype(str)\n",
        "df1[\"full_date\"] = pd.to_datetime(df[\"full_date\"], format = \"%d/%m/%Y\", dayfirst=True) #this doesn't change the date properly for some reason, but it works well enough to be able to work w the data\n",
        "\n",
        "#create is_holiday column\n",
        "df1[\"is_holiday\"] = df1[\"full_date\"].isin(holiday_cleaned[\"day_dt\"])\n",
        "\n",
        "#remove rows with ArrTime > 2400\n",
        "df1 = df1[(df1['ArrTime'] <= 2400)]\n",
        "df1 = df1[(df1['DepTime'] <= 2400)]\n",
        "\n",
        "df1.head(5)\n",
        "\n",
        "df2 = df1.drop(columns=[\"ActualElapsedTime\", \"AirTime\", \"ArrTime\", \"CRSArrTime\", \"CRSDepTime\", \"CRSElapsedTime\", \"CancellationCode\", \"FlightNum\", \"TailNum\",\"TaxiIn\", \"TaxiOut\",\"UniqueCarrier\"])\n",
        "\n",
        "# one more column for number of flights in that day\n",
        "df2\n",
        "df2[\"NumFlightsToday\"] = df2.groupby([\"full_date\"])[\"full_date\"].transform('count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArrDelay</th>\n",
              "      <th>Cancelled</th>\n",
              "      <th>CarrierDelay</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>DayofMonth</th>\n",
              "      <th>DepDelay</th>\n",
              "      <th>DepTime</th>\n",
              "      <th>Dest</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Diverted</th>\n",
              "      <th>LateAircraftDelay</th>\n",
              "      <th>Month</th>\n",
              "      <th>NASDelay</th>\n",
              "      <th>Origin</th>\n",
              "      <th>SecurityDelay</th>\n",
              "      <th>WeatherDelay</th>\n",
              "      <th>Year</th>\n",
              "      <th>full_date</th>\n",
              "      <th>is_holiday</th>\n",
              "      <th>NumFlightsToday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>81.0</td>\n",
              "      <td>1616.0</td>\n",
              "      <td>DFW</td>\n",
              "      <td>802.0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>6</td>\n",
              "      <td>23.0</td>\n",
              "      <td>ORD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2006</td>\n",
              "      <td>2006-06-21</td>\n",
              "      <td>False</td>\n",
              "      <td>560760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1524.0</td>\n",
              "      <td>MSP</td>\n",
              "      <td>528.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DTW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1997</td>\n",
              "      <td>1997-09-16</td>\n",
              "      <td>False</td>\n",
              "      <td>423929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>70.0</td>\n",
              "      <td>2210.0</td>\n",
              "      <td>DTW</td>\n",
              "      <td>229.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MDW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1991</td>\n",
              "      <td>1991-02-05</td>\n",
              "      <td>False</td>\n",
              "      <td>402346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>FLL</td>\n",
              "      <td>992.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PHL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1997</td>\n",
              "      <td>1997-02-01</td>\n",
              "      <td>False</td>\n",
              "      <td>423929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>CLE</td>\n",
              "      <td>475.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BDL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1989</td>\n",
              "      <td>1989-02-21</td>\n",
              "      <td>False</td>\n",
              "      <td>395876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9882792</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1730.0</td>\n",
              "      <td>PIT</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DTW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008</td>\n",
              "      <td>2008-10-02</td>\n",
              "      <td>False</td>\n",
              "      <td>549232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9882793</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>9.0</td>\n",
              "      <td>811.0</td>\n",
              "      <td>DEN</td>\n",
              "      <td>641.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DFW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1997</td>\n",
              "      <td>1997-12-25</td>\n",
              "      <td>True</td>\n",
              "      <td>423929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9882794</th>\n",
              "      <td>-10.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>551.0</td>\n",
              "      <td>DFW</td>\n",
              "      <td>984.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MCO</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1992</td>\n",
              "      <td>1992-08-30</td>\n",
              "      <td>False</td>\n",
              "      <td>402151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9882795</th>\n",
              "      <td>-4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>620.0</td>\n",
              "      <td>SMF</td>\n",
              "      <td>389.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ONT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2001</td>\n",
              "      <td>2001-05-03</td>\n",
              "      <td>False</td>\n",
              "      <td>457210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9882796</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2026.0</td>\n",
              "      <td>DEN</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12</td>\n",
              "      <td>7.0</td>\n",
              "      <td>SEA</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005-12-13</td>\n",
              "      <td>False</td>\n",
              "      <td>558975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9674807 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ArrDelay  Cancelled  CarrierDelay  DayOfWeek  DayofMonth  DepDelay  \\\n",
              "0            90.0          0           0.0          3          21      81.0   \n",
              "1            59.0          0           NaN          2          16      14.0   \n",
              "3            80.0          0           NaN          2           5      70.0   \n",
              "4             5.0          0           NaN          6           1      20.0   \n",
              "5            10.0          0           NaN          2          21       0.0   \n",
              "...           ...        ...           ...        ...         ...       ...   \n",
              "9882792       5.0          0           NaN          4           2      10.0   \n",
              "9882793       5.0          0           NaN          4          25       9.0   \n",
              "9882794     -10.0          0           NaN          7          30       1.0   \n",
              "9882795      -4.0          0           NaN          4           3       0.0   \n",
              "9882796      18.0          0           0.0          2          13      11.0   \n",
              "\n",
              "         DepTime Dest  Distance  Diverted  LateAircraftDelay  Month  NASDelay  \\\n",
              "0         1616.0  DFW     802.0         0               67.0      6      23.0   \n",
              "1         1524.0  MSP     528.0         0                NaN      9       NaN   \n",
              "3         2210.0  DTW     229.0         0                NaN      2       NaN   \n",
              "4         1800.0  FLL     992.0         0                NaN      2       NaN   \n",
              "5         1300.0  CLE     475.0         0                NaN      2       NaN   \n",
              "...          ...  ...       ...       ...                ...    ...       ...   \n",
              "9882792   1730.0  PIT     201.0         0                NaN     10       NaN   \n",
              "9882793    811.0  DEN     641.0         0                NaN     12       NaN   \n",
              "9882794    551.0  DFW     984.0         0                NaN      8       NaN   \n",
              "9882795    620.0  SMF     389.0         0                NaN      5       NaN   \n",
              "9882796   2026.0  DEN    1024.0         0               11.0     12       7.0   \n",
              "\n",
              "        Origin  SecurityDelay  WeatherDelay  Year  full_date  is_holiday  \\\n",
              "0          ORD            0.0           0.0  2006 2006-06-21       False   \n",
              "1          DTW            NaN           NaN  1997 1997-09-16       False   \n",
              "3          MDW            NaN           NaN  1991 1991-02-05       False   \n",
              "4          PHL            NaN           NaN  1997 1997-02-01       False   \n",
              "5          BDL            NaN           NaN  1989 1989-02-21       False   \n",
              "...        ...            ...           ...   ...        ...         ...   \n",
              "9882792    DTW            NaN           NaN  2008 2008-10-02       False   \n",
              "9882793    DFW            NaN           NaN  1997 1997-12-25        True   \n",
              "9882794    MCO            NaN           NaN  1992 1992-08-30       False   \n",
              "9882795    ONT            NaN           NaN  2001 2001-05-03       False   \n",
              "9882796    SEA            0.0           0.0  2005 2005-12-13       False   \n",
              "\n",
              "         NumFlightsToday  \n",
              "0                 560760  \n",
              "1                 423929  \n",
              "3                 402346  \n",
              "4                 423929  \n",
              "5                 395876  \n",
              "...                  ...  \n",
              "9882792           549232  \n",
              "9882793           423929  \n",
              "9882794           402151  \n",
              "9882795           457210  \n",
              "9882796           558975  \n",
              "\n",
              "[9674807 rows x 20 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1.to_csv(\"clean_airline.csv\")\n",
        "holiday_cleaned.to_csv(\"clean_holiday.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Export to S3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s3output = glueContext.getSink(\n",
        "  path=\"s3://factors-cleaned-data-bucket\",\n",
        "  connection_type=\"s3\",\n",
        "  updateBehavior=\"UPDATE_IN_DATABASE\",\n",
        "  partitionKeys=[],\n",
        "  compression=\"snappy\",\n",
        "  enableUpdateCatalog=True,\n",
        "  transformation_ctx=\"s3output\",\n",
        ")\n",
        "s3output.setFormat(\"glueparquet\")\n",
        "s3output.writeFrame(DyF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx6DHHA2eoSZ"
      },
      "source": [
        "# **Data Visualization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Line Graph (NEW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def day_of_year_list(timestamps):\n",
        "    day_of_year_list = [timestamp.dayofyear for timestamp in timestamps]\n",
        "    day_of_year_list = [day - 1 for day in day_of_year_list]\n",
        "    return day_of_year_list\n",
        "\n",
        "#creating  line graph\n",
        "df_year = 1999\n",
        "\n",
        "plot_data = df1.groupby(\"full_date\")[\"full_date\"].count()\n",
        "plot_df = pd.DataFrame({'full_date':plot_data.index,'flight_count':plot_data.values})\n",
        "plot_df_1999 = plot_df[plot_df[\"full_date\"].dt.year == df_year]\n",
        "\n",
        "x_axis = plot_df_1999[\"full_date\"]\n",
        "y_axis = plot_df_1999[\"flight_count\"]\n",
        "\n",
        "#creating holiday markers\n",
        "holiday1 = holiday[holiday[\"cal_year\"] == df_year]\n",
        "holiday2 = holiday1[[\"holiday_us\", \"day_of_year\"]]\n",
        "holiday_label_list = []\n",
        "holiday_labels = []\n",
        "for index, row in holiday2.iterrows():\n",
        "    if pd.isna(row[\"holiday_us\"]):\n",
        "        holiday_label_list.append(\"\")\n",
        "    else:\n",
        "        holiday_label_list.append(row[\"holiday_us\"])\n",
        "        holiday_labels.append(row[\"day_of_year\"]-1)\n",
        "\n",
        "plt.figure(figsize=(25, 5))\n",
        "plt.plot(x_axis, y_axis,  marker=\"o\", markevery=holiday_labels, mfc = \"r\")\n",
        "for x, y, text in zip(x_axis, y_axis, holiday_label_list):\n",
        "    plt.text(x, y, text)\n",
        "\n",
        "plt.xticks(rotation=50, ha=\"right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from datetime import timedelta\n",
        "\n",
        "def get_week_dates(timestamps):\n",
        "    holiday_dates = {}\n",
        "    for timestamp in timestamps:\n",
        "        holiday_dates[timestamp] = []\n",
        "        holiday_dates[timestamp].append(timestamp)\n",
        "        for i in range(1,8):\n",
        "            i_days_before = timestamp - timedelta(days=i)\n",
        "            i_days_after = timestamp + timedelta(days=i)\n",
        "            holiday_dates[timestamp].append(i_days_before)\n",
        "            holiday_dates[timestamp].append(i_days_after)\n",
        "    return holiday_dates\n",
        "\n",
        "def remove_duplicate(timestamps):\n",
        "    timestamp_list = []\n",
        "    for timestamp in timestamps:\n",
        "        if timestamp not in timestamp_list:\n",
        "            timestamp_list.append(timestamp)\n",
        "    return timestamp_list\n",
        "\n",
        "                                                                                                                                                                            \n",
        "\n",
        "result_df = pd.DataFrame(columns=[\"year\",\"holiday w/ highest effect\",\"diff_high\", \"holiday w/ worst effect\",\"diff_low\"])\n",
        "\n",
        "year_list = list(range(1988,2008))\n",
        "for year in year_list:\n",
        "    plot_df_year = plot_df[plot_df[\"full_date\"].dt.year == year]\n",
        "    holiday1 = holiday[holiday[\"cal_year\"] == year]\n",
        "\n",
        "    analysis_df1 = holiday1[[\"day_dt\",\"holiday_us\"]][holiday1[[\"day_dt\",\"holiday_us\"]][\"holiday_us\"].notna()]\n",
        "    analysis_df2 =  pd.to_datetime(analysis_df1['day_dt'],dayfirst=True)\n",
        "    analysis_df2_list = analysis_df2.to_list()\n",
        "\n",
        "    analysis_df2_dict = get_week_dates(analysis_df2_list)\n",
        "\n",
        "    analysis_df3 = pd.DataFrame(columns=['holiday_date','flight_count_average_2_weeks','max','min'])\n",
        "\n",
        "    for holidayx, date_list in analysis_df2_dict.items():\n",
        "        holiday_flight_total = 0\n",
        "        holiday_max = 0\n",
        "        holiday_min = 1000000\n",
        "        for date2 in date_list:\n",
        "            day_flight_total = plot_df[\"flight_count\"][plot_df[\"full_date\"]== date2]\n",
        "            day_flight_total = day_flight_total.iloc[0]\n",
        "            holiday_flight_total += day_flight_total\n",
        "            if day_flight_total > holiday_max:\n",
        "                holiday_max = day_flight_total\n",
        "            if day_flight_total < holiday_min:\n",
        "                holiday_min = day_flight_total\n",
        "            flight_count_average = holiday_flight_total/15\n",
        "            flight_count_average = flight_count_average.round()\n",
        "        temp_df = pd.DataFrame({'holiday_date':[holidayx],'flight_count_average_2_weeks':[flight_count_average], 'max':[holiday_max], 'min':[holiday_min]})\n",
        "        analysis_df3 = pd.concat([analysis_df3,temp_df])\n",
        "        \n",
        "\n",
        "    diff_column = pd.DataFrame(columns=['diff_from_avg'])\n",
        "    for index, row in analysis_df3.iterrows():\n",
        "        diff_from_avg = row[1] - plot_df_year[\"flight_count\"].mean()\n",
        "        temp_df = pd.DataFrame({'diff_from_avg':[diff_from_avg]})\n",
        "        diff_column = pd.concat([diff_column,temp_df])\n",
        "\n",
        "    analysis_df3 = pd.concat([analysis_df3, diff_column], axis=1)\n",
        "\n",
        "    highest_holiday = \"\"\n",
        "    lowest_holiday = \"\"\n",
        "    highest_holiday_diff = 0\n",
        "    lowest_holiday_diff = 100000\n",
        "    for index, row in analysis_df3.iterrows():\n",
        "        diff = row[4]\n",
        "        holiday_date = row[0]\n",
        "        if diff < lowest_holiday_diff:\n",
        "            lowest_holiday_diff = diff\n",
        "            lowest_holiday = holiday_date\n",
        "        if diff > highest_holiday_diff:\n",
        "            highest_holiday_diff = diff\n",
        "            highest_holiday = holiday_date\n",
        "\n",
        "    # print(\"Mean of all daily flights for year \" + str(year) + \": \" + str(plot_df_year[\"flight_count\"].mean()))\n",
        "    # print(\"Min of all daily flights for year \" + str(year) + \": \" + str(plot_df_year[\"flight_count\"].min()))\n",
        "    # print(\"Max of all daily flights for year \" + str(year) + \": \" + str(plot_df_year[\"flight_count\"].max()))\n",
        "\n",
        "    temp_df = pd.DataFrame({'year':[year],'holiday w/ highest effect':[highest_holiday],'diff_high':[highest_holiday_diff], 'holiday w/ worst effect':[lowest_holiday], \"diff_low\":[lowest_holiday_diff]})\n",
        "    result_df = pd.concat([result_df,temp_df])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_df1 = result_df\n",
        "result_df1 = result_df1.reset_index(drop=True)\n",
        "for index, row in result_df1.iterrows():\n",
        "    holiday_name_high = holiday_cleaned.loc[holiday_cleaned[\"day_dt\"]==row[1], \"holiday_us\"].iloc[0]\n",
        "    result_df1.at[index, 'holiday w/ highest effect'] = holiday_name_high\n",
        "    holiday_name_low = holiday_cleaned.loc[holiday_cleaned[\"day_dt\"]==row[3], \"holiday_us\"].iloc[0]\n",
        "    result_df1.at[index, 'holiday w/ worst effect'] = holiday_name_low\n",
        "result_df1\n",
        "result_df1['holiday w/ worst effect'].value_counts()\n",
        "\n",
        "\n",
        "result_df2 = result_df1['holiday w/ worst effect'].value_counts().rename_axis(\"holiday w/ worst effect\").reset_index(name=\"count\")\n",
        "high_holiday_list = result_df2[\"holiday w/ worst effect\"].to_list()\n",
        "high_count_list = result_df2[\"count\"].to_list()\n",
        "\n",
        "y = np.array(high_count_list)\n",
        "mylabels = high_holiday_list\n",
        "\n",
        "plt.pie(y, labels = mylabels)\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coqwHVhte0lO"
      },
      "source": [
        "## Line Graph (OLD)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "OxeVJNT5vXua",
        "outputId": "bebef2fc-ea13-4760-b3fa-3fe1564ec18e"
      },
      "outputs": [],
      "source": [
        "# #function for markers\n",
        "# def day_of_year(date_str):\n",
        "#     month, day, year = map(int, date_str.split('/'))\n",
        "#     days_in_month = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334]\n",
        "#     if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
        "#         days_in_month[2] += 1  # Leap year adjustment\n",
        "#     return days_in_month[month - 1] + day - 1  # Subtract 1 to convert to 0-based indexing\n",
        "\n",
        "                                                                                                                                                                                                 \n",
        "\n",
        "# year_to_visualize = 1999\n",
        "# year_to_visualize_string = \"1999\"\n",
        "# df_year = df1[(df1['Year'] == year_to_visualize)]\n",
        "\n",
        "# flights_total = df_year.groupby('full_date').size()\n",
        "\n",
        "# holidays = df_year[df_year['is_holiday'] == True]\n",
        "# holidays = holidays.groupby('full_date').size()\n",
        "\n",
        "# holiday_df = holidays.to_frame()\n",
        "# holiday_df.reset_index(inplace=True)\n",
        "\n",
        "# holiday_list = holiday_df['full_date'].tolist()\n",
        "# print(holiday_list)\n",
        "# day_of_year_list = [day_of_year(date_str) for date_str in holiday_list]\n",
        "# # print(day_of_year_list)\n",
        "\n",
        "# plt.figure(figsize=(20, 12))\n",
        "# flights_total.plot(kind='line', marker='o', mfc = \"r\", color='blue', linestyle='-',markevery=day_of_year_list)\n",
        "\n",
        "# plt.xlabel('Time')\n",
        "# plt.ylabel('Number of Flights')\n",
        "# plt.title('Number of Domestic Flights from 1987 to 2008 with Holidays Highlighted')\n",
        "# plt.grid(True)\n",
        "# plt.legend(['Number of Flights', 'Holiday'])\n",
        "\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "history_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
